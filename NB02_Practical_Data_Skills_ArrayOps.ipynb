{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NB02_Practical_Data_Skills_ArrayOps.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "ax2kDy1jFMmS"
      },
      "source": [
        "# 5 Practical Skill 1 -- Array Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "sBODqXKOFMmT"
      },
      "source": [
        "## 5.1 Brief of Data Wrangling Tools with Discussion on When to Use Which"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "oJtE8KftFMmU"
      },
      "source": [
        "### 5.1.1 Small arrays and tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "mXtKwomNFMmV"
      },
      "source": [
        "Arrays are a very generic representation of the data. When an array is 2D,  it is often called a table. Usually, each row of a table represent one data sample, and each column of the table corresponds to one attribute of the data. Table data is perhaps the most the common simplest format of data. if all the values in the table are numerical,  and especially when we want to perform computations on the table a `numpy` array (see next subsection for details) is a convenient choice.\n",
        "\n",
        "On the other hand, a pandas dataframe should be considered if\n",
        "- the types of the values in the table are different,  or\n",
        "- we needed to deal with issues such as missing values,  or\n",
        "- It is convenient in the analysis to refer to the meaning of the attributes,  such as instead of being called “attribute-2”,  we want to call the attribute “petal_length”.\n",
        "\n",
        "An example of table data is the basic machine learning dataset \"Iris\".\n",
        "\n",
        "Note in the following example, `seaborn` is an accompany library facilitating quick prototyping and visualisation / inspection of `DataFrames` of the `pandas` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "ThIlTYhUFMmW",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "iris = sns.load_dataset('iris')\n",
        "iris.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "mf1lqW4yFMmZ"
      },
      "source": [
        "Alternatively, if we manage the data in numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "J9-HjlFxFMmZ",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_np = load_iris()\n",
        "print(iris_np.data.shape)\n",
        "print(iris_np.data[:5])\n",
        "print(iris_np.target[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "bsFjxUTtFMmc"
      },
      "source": [
        "### 5.1.2 Homogeneous Arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "7DzxwCASFMmd"
      },
      "source": [
        "When the data contains large amount of attributes, those attributes are organised in a spatially regular and meaningful way, then we use typical numerical multidimensional arrays. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "7cb3bBuHFMmd"
      },
      "source": [
        "The numerical computaiton library `numpy` provides convenient interfaces to efficient computation tools of manipulating arrays. Check the [online document][numpy-doc] for more details.\n",
        "\n",
        "[numpy-doc]:https://www.numpy.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "374EVZIWFMme"
      },
      "source": [
        "> Numpy has a sister library, `scipy`, which contains higher level (overlapping to an extent) functions. E.g. `numpy` performs linear algebric operators, e.g. compute $C$ in $A \\times B \\rightarrow C$, where $A$  and $B$ are matrices or vectors, while `scipy` can do the inverse computation, i.e. finding out $A$, where $A \\times B \\rightarrow C$)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "8lFH7mTcFMmf"
      },
      "source": [
        "#### Example of image pixels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "ie4wQoNvNj-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_sample_images\n",
        "ims = load_sample_images()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "9w5cvN0LFMmg",
        "colab": {}
      },
      "source": [
        "image_0 = ims.images[0]\n",
        "print(image_0.shape)\n",
        "# White-board illustration-1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Genu6Er9Nj-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(image_0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "iRDY5-OJNj-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_1 = ims.images[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "tGxr1uPsNj-2",
        "colab": {}
      },
      "source": [
        "images = np.stack((image_0, image_1)) \n",
        "# Stack: combine samples - one more dimension\n",
        "# Continue White-board illustration-1\n",
        "print(images.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "ssp6AHMDFMmi",
        "colab": {}
      },
      "source": [
        "plt.imshow(images[0])\n",
        "plt.show()\n",
        "plt.imshow(images[1])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "sGEOR8w7FMmk"
      },
      "source": [
        "Let's apply a partial blue-filter and a total red filter to the two images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "y3ne6qQiFMml",
        "colab": {}
      },
      "source": [
        "image_0[100:150, 100:500, 0:2] = 0\n",
        "plt.imshow(image_0)\n",
        "plt.show()\n",
        "# White board illustration-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "WKvsd5jfNj-7",
        "colab": {}
      },
      "source": [
        "# Guess the effect?\n",
        "image_1[:, :, 1:] = 0\n",
        "plt.imshow(image_1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "sA3oizsKFMmn"
      },
      "source": [
        "## 5.2 Advanced Array Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "0BuUtxD2FMmo"
      },
      "source": [
        "### 5.2.1 Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "-ab0wtRdFMmp"
      },
      "source": [
        "The following code is a simple visualiser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "U-3yPrCzFMmr",
        "colab": {}
      },
      "source": [
        "def show_array(a):\n",
        "    if a.ndim == 1: \n",
        "        a = a[:, np.newaxis]\n",
        "    fig, axes = plt.subplots(1)\n",
        "    fig.set_size_inches(a.shape[1]/2, a.shape[0]/2)\n",
        "    axes.imshow(a)\n",
        "    axes.set_xticks(np.arange(a.shape[1]))\n",
        "    axes.set_yticks(np.arange(a.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "9Km8TwJWFMmt"
      },
      "source": [
        "Study the following example, and perform the following exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "A40ZSLF9FMmu",
        "colab": {}
      },
      "source": [
        "a = np.zeros((10, 1))\n",
        "a[5:8]=1\n",
        "show_array(a)\n",
        "\n",
        "a = np.zeros((10, 1))\n",
        "a[3:8:2]=1\n",
        "show_array(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "gEj7Y6oHFMmw"
      },
      "source": [
        "__EXERCISE__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "IMrlLkHnFMmw",
        "colab": {}
      },
      "source": [
        "# Replace ... to produce (1) and (2) (in two experiments)\n",
        "a = np.zeros((10, 1))\n",
        "a[...]=1\n",
        "show_array(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "F8d_z9mtFMmy",
        "colab": {}
      },
      "source": [
        "# Replace ... to produce (3) and (4) (in two experiments)\n",
        "a = np.zeros((10, 10))\n",
        "a[1::3, ::2]=1\n",
        "show_array(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "MdGSlWITFMm0",
        "colab": {}
      },
      "source": [
        "# Consider the `im` array\n",
        "ims = load_sample_images()\n",
        "im = ims.images[0][:,:, 0]/255\n",
        "plt.imshow(im, cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "# Explain what you see in im_h\n",
        "im_h = im[:, 1:] - im[:, :-1]\n",
        "plt.imshow(im_h, cmap=\"gray\", vmax=1.0, vmin=-1.0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "71khDpBZNj_L",
        "colab_type": "text"
      },
      "source": [
        "### 5.2.2 View and Copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "g1OBvfuyNj_M",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "When an indexing operation refers to a \"regular\" block of memory.   Check the [tutorial][view-copy-tut] for more details.\n",
        "\n",
        "> Whiteboard illustration - 3 \n",
        "\n",
        "[view-copy-tut]:https://www.tutorialspoint.com/numpy/numpy_copies_and_views.htm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "ilOFRrocNj_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regular: a slice\n",
        "a = np.zeros((5, 10))\n",
        "b = a[2]\n",
        "b[2] = 999\n",
        "print(b)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "3mm-j6YGNj_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regular: a slice of a slice\n",
        "a = np.zeros((5, 10))\n",
        "b = a[2, 3:6]\n",
        "b[2] = 99\n",
        "print(b)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "BI7jHZBENj_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regular: a slice of a slice (both of multiple indexes)\n",
        "a = np.zeros((5, 10))\n",
        "b = a[2:3, 3:6]\n",
        "b[0, 2] = 99\n",
        "print(b)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "zfoLVHG-Nj_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regular: a slice of a slice (both of multiple indexes)\n",
        "a = np.zeros((5, 10))\n",
        "b = a[2:4, 3:8:2]\n",
        "b[0, 2] = 99\n",
        "print(b)\n",
        "print(a)\n",
        "b[...] = -1\n",
        "print(b)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "bsPQFdUUNj_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b is a COPY, complex index\n",
        "a = np.arange(50).reshape((5, 10))\n",
        "b1 = a[[2, 3], 3:8:2] \n",
        "b2 = a[2:4, 3:8:2] \n",
        "print(a)\n",
        "print(\"b1: complex indexes\")\n",
        "print(b1)\n",
        "print(\"b2: slicing\")\n",
        "print(b2)\n",
        "\n",
        "print(\"Setting b1\")\n",
        "b1[...] = 99\n",
        "print(b1)\n",
        "print(a)\n",
        "print(\"Setting b2\")\n",
        "b2[...] = 99\n",
        "print(b2)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "9a9d7dNWNj_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b is a COPY, complex, binary index\n",
        "a = np.arange(50).reshape((5, 10))\n",
        "c = np.arange(5)\n",
        "print(\"c\", c)\n",
        "b1 = a[c > 2, 3:8:2] \n",
        "b2 = a[3:, 3:8:2] \n",
        "print(a)\n",
        "print(\"b1: complex indexes\")\n",
        "print(b1)\n",
        "print(\"b2: slicing\")\n",
        "print(b2)\n",
        "\n",
        "print(\"Setting b1\")\n",
        "b1[...] = 99\n",
        "print(b1)\n",
        "print(a)\n",
        "print(\"Setting b2\")\n",
        "b2[...] = 99\n",
        "print(b2)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "Ek4ifa1AFMm2"
      },
      "source": [
        "### 5.2.3 Reducing and Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "X0DgNxJkFMm3"
      },
      "source": [
        "Reducing refers to some operation that summarise the values along a dimension, and store the result in a new array.  The new array will have one less dimension than the original one has. The summarisation operation include some often encountered ones such as taking the mean value or finding the median value or taking the minimum or maximum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "LRXnCsK9FMm3",
        "colab": {}
      },
      "source": [
        "# E.g. get the mean of each attribute of Iris Data\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_np = load_iris()\n",
        "iris_attr_mean = iris_np.data.mean(axis=0)\n",
        "print(iris_attr_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "nzNOMsg1FMm5"
      },
      "source": [
        "__EXERCISE__\n",
        "\n",
        "Compute the max and min value of each attribute of the Iris dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "yCEM9NEDFMm6"
      },
      "source": [
        "Broadcasting is an easy way to specify element-wise computation between two arrays.  In a sense, the correspondence between a large array and a small array in broadcasting mirrors the relationship between the two arrays in reducing. Please check the document or a [tutorial][bd-tut] for more detials.\n",
        "\n",
        "[bd-tut]:https://www.tutorialspoint.com/numpy/numpy_broadcasting.htm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "bff99xsQNj_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5], [6, 7, 8]])\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "e2bY1JV8Nj_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a + 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "7EKAnNTXNj_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a + np.array([10, 20, 30])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "qLCGLljuFMm7",
        "colab": {}
      },
      "source": [
        "# E.g. to take off the minimum value of each attribute from each data sample in Iris, so in the processed data \n",
        "# the minimum value of each attribute is 0.\n",
        "\n",
        "iris_np_zero_min = iris_np.data - iris_np.data.min(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "H8ULGHILFMm9",
        "colab": {}
      },
      "source": [
        "plt.boxplot(iris_np_zero_min)\n",
        "plt.xlabel(\"Attributes\")\n",
        "plt.show() # Note the absolute minimum value of each attribute."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "Rqu3ZyCZFMm_"
      },
      "source": [
        "__EXERCISE__\n",
        "\n",
        "Normalise the iris data so that each attribute is between $[0, 1]$.\n",
        "\n",
        "HINT: the range is `max - min`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "MaFMGwBOFMnA"
      },
      "source": [
        "# Real-world Data Wrangling Example 1: Sea Surface Temperature Records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "2cGzF4DfFMnA",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    import netCDF4\n",
        "except:\n",
        "    !pip install netcdf4\n",
        "    \n",
        "try:\n",
        "    import plotly\n",
        "    major_plotly_version = int(plotly.__version__.split('.')[0])\n",
        "    assert major_plotly_version >= 4\n",
        "except:\n",
        "    !pip install plotly==4.1.0\n",
        "    \n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import xarray as xr  \n",
        "COLAB = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "_DnYpcw1FMnE"
      },
      "source": [
        "In this example, we practice our skills to manipulate large complex array data. We consider the global sea surface temperature (SST) records over the past 100 years. The data consists of measurements conducted by various devices including commercial/military vehicles, satellites, etc. See [Wikipedia][sst] document for further information. The data we will use is from [NOAA/ERSL/PSD][esrl] (The US National Oceanic and Atmospheric Administration Earth System Research Laboratory's Physical Sciences Division). Data source: [link](https://www.esrl.noaa.gov/psd/data/gridded/).\n",
        "\n",
        "The data is in NetCDF format. They are essentially high-dimensional arrays. However, the dimensions are of physical significance (e.g. longitudes/longitudes/years). We will use the `xarray` library to process the arrays. At the backend, `xarray` uses `netcdf` library to access the data.\n",
        "\n",
        "[esrl]:https://www.esrl.noaa.gov/psd/ \n",
        "[sst]:https://en.wikipedia.org/wiki/Sea_surface_temperature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "xhcg6T7yFMnF",
        "colab": {}
      },
      "source": [
        "# Duplicate for convenient reference not need to execute\n",
        "try:\n",
        "    import netCDF4\n",
        "except:\n",
        "    !pip install netcdf4\n",
        "import xarray as xr    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "Tp5XmOaEFMnH"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "hYuA3o7lFMnI"
      },
      "source": [
        "It is a good habit to maintain the data and the code in an ordered away in the file system.  It allows you to use cloud computing facilities (where you may not be able to store data for long) and make it easier to back up all your work.\n",
        "\n",
        "In the following code cell, we try to open the dataset file at a designated location.  If the file does not exist, we will download the raw data.  If the location does not exist, we will create the folders accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "tKETJwC3FMnJ",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "DATA_URL = 'ftp://ftp.cdc.noaa.gov/Datasets/COBE2/sst.mon.mean.nc'\n",
        "DATA_FILENAME = \"sst.mon.mean.nc\"\n",
        "\n",
        "data_dir = Path(\"./data/global-sst\")\n",
        "# Create dir structure if not existing\n",
        "data_dir.mkdir(parents=True, exist_ok=True) \n",
        "filepath = data_dir / DATA_FILENAME"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrM0lTx2cPoQ",
        "colab_type": "text"
      },
      "source": [
        "Check if the dataset file exists, if not, download the file.\n",
        "\n",
        "HINT: If used often, you can also maintain a file in your own google drive (the file-id I provided in class won't persist). To access your GoogleDrive files, you can checkout a code-snippet provided by colab that \"mounts\" the drive (then you can view it as a local folder). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0zvOy-hPOtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Data Manage\n",
        "#@markdown Check the data file and download or access from Google Drive. Choose the data source\n",
        "#@markdown You need to authorise colab to activate the Google Drive function\n",
        "#@markdown using your Google Account\n",
        "data_source = \"Existing\"  #@param ['Existing', 'Google Drive', 'NOAA/ERSL']\n",
        "#@markdown --- \n",
        "\n",
        "if not filepath.exists():\n",
        "    if data_source == 'Existing':\n",
        "        raise ValueError(\"File doesn't exist, plese choose a source to get the file\")\n",
        "    elif data_source == \"Google Drive\":\n",
        "        # Install the PyDrive wrapper & import libraries.\n",
        "        # This only needs to be done once per notebook.\n",
        "        !pip install -U -q PyDrive\n",
        "        from pydrive.auth import GoogleAuth\n",
        "        from pydrive.drive import GoogleDrive\n",
        "        from google.colab import auth\n",
        "        from oauth2client.client import GoogleCredentials\n",
        "\n",
        "        # Authenticate and create the PyDrive client.\n",
        "        # This only needs to be done once per notebook.\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        drive = GoogleDrive(gauth)\n",
        "\n",
        "        # Download a file based on its file ID.\n",
        "        #\n",
        "        # A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "        file_id = '1WNKcsEz2c69RsFuHLGUDYmydq5wukmiY'\n",
        "        downloaded = drive.CreateFile({'id': file_id})\n",
        "        downloaded.GetContentFile(str(filepath))\n",
        "    elif data_source == \"NOAA/ERSL\":\n",
        "        import urllib.request\n",
        "        urllib.request.urlretrieve(DATA_URL, str(filepath))\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "j9LcDsiuFMnO"
      },
      "source": [
        "Now we are ready to load the multi-dimensional array of SST data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "xIH5gwEbFMnP",
        "colab": {}
      },
      "source": [
        "data = xr.open_dataset(str(filepath.absolute()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "01mQ08yUFMnQ"
      },
      "source": [
        "Now we have `data` -- the object returned by opening the dataset. So we can simply let the Notebook to “print out” the object to get some basic information about it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "jG6pPpR0FMnR"
      },
      "source": [
        "## Initial Exam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "HbMKJ8jKFMnR",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "cprN-dSJFMnT"
      },
      "source": [
        "From the brief description we can figure out that the essential information of this data set is stored in: \n",
        "```\n",
        "Data variables:\n",
        "    sst      (time, lat, lon) float32 ...\n",
        "```\n",
        "So let us further examine this sub-field of the `data` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "kI6HItmIFMnU",
        "colab": {}
      },
      "source": [
        "data.sst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "P96D62i8FMnV"
      },
      "source": [
        "We can consider `data.sst` as a normal three dimensional array (similar to `numpy.ndarray`), check its shape and take one slice to visualise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "DiumgfEHFMnW",
        "colab": {}
      },
      "source": [
        "print(\"SST data shape\", data.sst.shape)\n",
        "print(\"The slice of SST data of time-dimension[0] shape:\", data.sst[0].shape)\n",
        "print(\"Visualise the slice as an image\")\n",
        "plt.imshow(data.sst[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "_jR8BypdFMnb"
      },
      "source": [
        "Well, the figure looks ... oceanic. But the dataset provides more information about the axes. Let us investigate.\n",
        "\n",
        "The `xarray` library wraps the data in an object `xarray.DataArray`, which provides us with a more meaningful way of accessing the data by referring to the axes concerning their semantics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "1QaO6s3BFMnc"
      },
      "source": [
        "Let us check the dimension of `time`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "v5CwYcNmFMnd",
        "colab": {}
      },
      "source": [
        "data.sst.time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "IrdOxNAuFMne"
      },
      "source": [
        "Interestingly, this dimension itself is represented using another `DataArray` object.  We notice its data type (`dtype`) is `datetime64[ns]`, which is a numpy class representing a precise moment.  So let us try to use a time object to index the array (The object was new to me as well,  I just googled using the keywords \"numpy datetime64\"). \n",
        "\n",
        "Note the `squeeze` removes singular dimensions from the result slice. Check `numpy.squeeze` for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "d09l4UVzFMnf",
        "colab": {}
      },
      "source": [
        "day = np.datetime64('1980-12-01')\n",
        "sst_day = data.sst[data.sst.time == day].squeeze()\n",
        "plt.imshow(sst_day.values)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "8xKDspe8FMng"
      },
      "source": [
        "Since the sea surface temperature data are measurements on a grid, sometimes it is useful to create coordinate grids for the individual measurements. E.g. the DataArray contains\n",
        "\n",
        "| .       |    Logitudes| 0| 1| 2| 3| 4| \n",
        "|-|-|-|-|-|-|-|\n",
        "|Latitudes|            .| .| .| .| .| .|\n",
        "|0|.|$v_{0,0}$|v|v|v|v|\n",
        "|1|.|v|v|v|v|$v_{1,4}$|\n",
        "\n",
        "For some convenience, we want to represent the data in one long table\n",
        "\n",
        "|Latitudes|Logitudes|Value|\n",
        "|-|-|-|\n",
        "|0|0|$v_{0, 0}$|\n",
        "|0|1|$v_{0, 1}$|\n",
        "...\n",
        "\n",
        "\n",
        "The table has the same number of rows as the number of total elements in the original 2D array.\n",
        "\n",
        "In `numpy`, the coordinates can be constructed using `meshgrid`, please google and try.\n",
        "```python\n",
        "xx, yy = np.meshgrid(np.array([0, 1, 2]), np.array([99, 100]))\n",
        "print(\"x-grid\")\n",
        "print(xx)\n",
        "print(\"y-grid\")\n",
        "print(yy)\n",
        "print(\"coordinate-grid\")\n",
        "print(np.stack((xx.flatten(), yy.flatten())))\n",
        "```\n",
        "\n",
        "As to `xarray.DataArray`, the object provides a direct method to generate a table with coordinate grids via its `to_dataframe()` function. Note the generated frame will have \"multiple index\" (working similary as the latitudes and logitudes as in the original data), we need to `reset_index()` to have the `lat` and `lon` as independent columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "O2QB0P4LFMnh",
        "colab": {}
      },
      "source": [
        "sst_day_df = sst_day[::3, ::3].to_dataframe() #::3, take measure \n",
        "# sample every 3 locations, to reduce computational demand for visualisation\n",
        "sst_day_df.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "3ug-Iv0gNj_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sst_day_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "ozBNrMyKFMni"
      },
      "source": [
        "We can use plotly to show interactive plot of the SST data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "msB_bPemFMnj",
        "colab": {}
      },
      "source": [
        "DRAW_EXPRESS = True\n",
        "if DRAW_EXPRESS:\n",
        "    # px.set_mapbox_access_token(\"pk.eyJ1IjoianVuankwMDciLCJhIjoiY2p6aWs5bDZxMDA1ZDNjczM1cmFiMjc5MCJ9.ixcf00oF_QL5eg44OP9fuQ\")\n",
        "    fig = px.scatter_geo(sst_day_df, lat=\"lat\", lon=\"lon\", color=\"sst\", \n",
        "                         color_continuous_scale=px.colors.sequential.Viridis)\n",
        "    fig.show()\n",
        "else:\n",
        "    # More control. But verbose coding.\n",
        "    fig_geo_data = go.Scattergeo(\n",
        "        lat=sst_day_df.lat, \n",
        "        lon=sst_day_df.lon, \n",
        "        text=[\"sst={:.2f}\".format(s_) for s_ in sst_day_df.sst],\n",
        "        marker=dict(color=sst_day_df.sst, colorscale=\"Viridis\"),\n",
        "        name=\"Global Sea Surface Temperature in Dec 1980\")\n",
        "    fig = go.Figure(data=fig_geo_data)\n",
        "    fig.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "W1Sp9zM0FMnl"
      },
      "source": [
        "## Investigate an Area of Interest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "ppf7zk8zFMnl"
      },
      "source": [
        "Partially to practice array operation skills and partially to investigate an idea, let us extract the SST from a tropical sea area. We construct boolean indexes to take SST values from east tropical pacific ocean (you can try your own idea, e.g. check the \"Nino 3.4 Region\" related to [El Nino][elnino]).\n",
        "\n",
        "[elnino]:https://en.wikipedia.org/wiki/El_Ni%C3%B1o"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "y5W634NdFMnm",
        "colab": {}
      },
      "source": [
        "# Specify the boundaries of the area\n",
        "lat_north = 10.5\n",
        "lat_south = -10.5\n",
        "lon_west = 230.5\n",
        "lon_east = 260.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "Xf1r-julFMno"
      },
      "source": [
        "Indexing by boolean tests works similarily in mainstream array tools. See this [document][adv-arr-index] of numpy.\n",
        "\n",
        "[adv-arr-index]:https://docs.scipy.org/doc/numpy-1.13.0/user/basics.indexing.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "JtN3nhP4FMno",
        "colab": {}
      },
      "source": [
        "lat_index = (lat_south <= data.sst.lat) * (data.sst.lat <= lat_north)\n",
        "lon_index = (lon_west <= data.sst.lon) * (data.sst.lon <= lon_east)\n",
        "interested_sea_area = data.sst[:, lat_index, lon_index]\n",
        "print(interested_sea_area)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "1ZuaGwcZFMnq"
      },
      "source": [
        "The brief information shows the area is a cut-off block from the global SST data of 22 latitudes and 31 longitudes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "gW4Dor-lFMnq",
        "colab": {}
      },
      "source": [
        "# Heatmap is another intuitive visualisation for array data.\n",
        "fig = go.Figure(data=[go.Heatmap(x=interested_sea_area.lon,\n",
        "                                 y=interested_sea_area.lat,\n",
        "                                 z=interested_sea_area[0,:,:])])\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "1XXTgbNaFMns"
      },
      "source": [
        "## Examine Trend in Time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "63Wl01KzFMns"
      },
      "source": [
        "Let us examine if there is any time-related trend in the average temperature of the sea area. We need to compute the average SST value for the entire range of longitudes and latitudes. The computation needs to be done for every time spot. This corresponds to the \"reduce\" operation introduced above. The \"reducing\" applies to two dimensions: \"lon\" for longitudes and \"lat\" for latitudes. After the operation, we will arrive at a series (1-D) of average SST values, each corresponding to one time of record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "le64tkV1FMns",
        "colab": {}
      },
      "source": [
        "interested_sea_area_sst_mean = interested_sea_area.mean(dim=[\"lon\", \"lat\"])\n",
        "print(interested_sea_area_sst_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "MuxZIP6oFMnu",
        "colab": {}
      },
      "source": [
        "scatter_data = go.Scatter(\n",
        "    x=interested_sea_area_sst_mean.time.to_series(), # so the time is human readable\n",
        "    y=interested_sea_area_sst_mean,\n",
        "    mode=\"markers+lines\")\n",
        "fig = go.Figure(data=[scatter_data])\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "Oiu6srC_FMnw"
      },
      "source": [
        "The data is obviously periodic -- the temperature rises and falls through a year. Let's take a look at a particular month, say December.\n",
        "\n",
        "Also for practice, lets work with `pandas.DataFrame`. Following an [example][pandas-datetime], we can add auxillary-columns to the dataframe to facilitate selection. Note the `apply` operation represents an important design pattern \"mapping/transforming\", where we give a list of object and a processing function. The data manager (here is the `DataFrame`) is responsible to pass each object in the list sequentially to the function to process.\n",
        "\n",
        "[pandas-datetime]:https://medium.com/datadriveninvestor/how-to-work-with-dates-in-pandas-like-a-pro-a84055a4819d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "FBq0jdVYFMny",
        "colab": {}
      },
      "source": [
        "sst_area_mean_df = interested_sea_area_sst_mean.to_dataframe()\n",
        "sst_area_mean_df.reset_index(inplace=True)\n",
        "\n",
        "sst_area_mean_df[\"month\"] = sst_area_mean_df[\"time\"].apply(lambda x:x.month) #\n",
        "sst_area_mean_df[\"year\"] = sst_area_mean_df[\"time\"].apply(lambda x:x.year) #\n",
        "sst_area_mean_df.head() # Now we have access to year and month"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "xar6x7FBFMnz"
      },
      "source": [
        "For exploratory purposes, I would adopt a quick dirty trick. We just take one particular month from each year and examine the trend of the average SST in the area of this month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "dx7AThqWFMn0",
        "colab": {}
      },
      "source": [
        "sst_area_mean12_df = sst_area_mean_df.loc[sst_area_mean_df[\"month\"]==12]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "kABbH_2LFMn1"
      },
      "source": [
        "Now let's visualise the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "zlHru7bRFMn2",
        "colab": {}
      },
      "source": [
        "DRAW_EXPRESS = True\n",
        "if DRAW_EXPRESS:\n",
        "    fig = px.scatter(sst_area_mean12_df, x=\"year\", y=\"sst\", trendline=\"ols\", range_x=[1849, 2020])\n",
        "    \n",
        "else:\n",
        "    fig = go.Figure(data=[go.Scatter(\n",
        "        x=sst_area_mean12_df[\"year\"], \n",
        "        y=sst_area_mean12_df[\"sst\"],\n",
        "        mode=\"markers+lines\")]\n",
        "    )\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "Ix71unJWFMn3"
      },
      "source": [
        "Any trend? How does the ocean affect us?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "xPqNmjPdFMn3"
      },
      "source": [
        "# Real-world Data Wrangling Example 2: World Food Production Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "iDTHZebqFMn4"
      },
      "source": [
        "The [data][unfao-crop-product-data] is from the United Nations Food and Agriculture Organisation ([UN FAO][unfao]). In this example, we will look at the [crop production][unfao-qc]. UNFAO publishes a wide range of data related to food, agriculture, as well as social development and human wellbeing. See their [document][unfao-crop-product-spec] for more information.\n",
        "\n",
        "[unfao-crop-product-data]:http://fenixservices.fao.org/faostat/static/bulkdownloads/Production_Crops_E_All_Data.zip\n",
        "[unfao]:http://www.fao.org/faostat/en/#home\n",
        "[unfao-qc]:http://www.fao.org/faostat/en/#data/QC\n",
        "[unfao-crop-product-spec]:http://fenixservices.fao.org/faostat/static/documents/QC/QC_methodology_e.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "L48FqriQFMn5"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "7gL5YgMdFMn5"
      },
      "source": [
        "At above, we fetch the data from the Internet if not existing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "_N-M6ziNFMn5",
        "colab": {}
      },
      "source": [
        "# ** Food Data File **\n",
        "FAOSTAT_DATA_URL = \"http://fenixservices.fao.org/faostat/static/bulkdownloads/\" +\\\n",
        "    \"Production_Crops_E_All_Data_(Normalized).zip\"\n",
        "DATA_FILENAME = \"Production_Crops_E_All_Data_(Normalized).zip\"\n",
        "data_dir = Path(\"./data/food-supply\")\n",
        "# Create dir structure if not existing\n",
        "data_dir.mkdir(parents=True, exist_ok=True) \n",
        "filepath = data_dir / DATA_FILENAME\n",
        "\n",
        "if not filepath.exists():\n",
        "    import urllib.request\n",
        "    urllib.request.urlretrieve(FAOSTAT_DATA_URL, str(filepath))    \n",
        "filepath = str(filepath.absolute()) \n",
        "\n",
        "# ** Country Code File ** (for visualisation)\n",
        "# Note the github raw file link is DIFFerent from the file-view link, see \n",
        "# the link below for more information:\n",
        "# https://stackoverflow.com/questions/4604663/download-single-files-from-github\n",
        "ISO_COUNTRY_CODE_CSV_URL = \\\n",
        "    \"https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv\"\n",
        "ISO_COUNTRY_CODE_CSV_FILENAME = \"ISO-3166.csv\"\n",
        "\n",
        "iso_country_code_csv_filename = data_dir / ISO_COUNTRY_CODE_CSV_FILENAME\n",
        "if not iso_country_code_csv_filename.exists():\n",
        "    import urllib.request\n",
        "    urllib.request.urlretrieve(ISO_COUNTRY_CODE_CSV_URL, str(iso_country_code_csv_filename))\n",
        "iso_country_code_csv_filename = str(iso_country_code_csv_filename.absolute())\n",
        "iso_country_df = pd.read_csv(iso_country_code_csv_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "zJxHLXdwFMn7"
      },
      "source": [
        "## Initial Explore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "Qs-Pir_SFMn8"
      },
      "source": [
        "The FAO data is a table. We read it using `pandas.DataFrame`. `pandas` can handle compressed CSV file. However, the table contains characters not encoded in 'utf-8', we need to specify the encoding. \n",
        "\n",
        "Note for exploratory manipulation, I found it is handy to keep a cheatsheet of the data toolbox in reach. In this example, consider [this cheatsheet][pandas-cheatsheet].\n",
        "\n",
        "[pandas-cheatsheet]:https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "LsJOZOtJFMn8",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(filepath,\n",
        "    compression='zip', encoding = \"ISO-8859-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "39tFbNfSFMn9"
      },
      "source": [
        "First glance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "-n34epJ6FMn9",
        "colab": {}
      },
      "source": [
        "df.head() # What columns does it have? How the data samples look like?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "LuXMx4tVFMn-"
      },
      "source": [
        "There are about 10 informative columns. What is the size of the data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "CKDlsvkBFMn_",
        "colab": {}
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "LnA5QZ7zFMn_"
      },
      "source": [
        "That is a lot.  Let's narrow our focus for now. E.g. consider some `Item` in particular. However, even if we only look at the `Item` column, there still be 2M+ elements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "kjeshcjBFMoA",
        "colab": {}
      },
      "source": [
        "df['Item']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "3buUMHiyFMoB"
      },
      "source": [
        "But it seems there are a lot of repetitions. So the natural idea is to check what are the unique values in this list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "veL9QrJAFMoB",
        "colab": {}
      },
      "source": [
        "df['Item'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "LFhfTyKxFMoD"
      },
      "source": [
        "This looks much more manageable.\n",
        "\n",
        "Note the `unique` keyword is universal in many toolboxes. Usually, a library also provides a more convenient function that checks both the unique values and how many data samples having each value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "6wjmnY2SFMoD",
        "colab": {}
      },
      "source": [
        "df['Item'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "JLrTTltwFMoE"
      },
      "source": [
        "To begin with, let us consider one item, \"Wheat\" (\"Bananas\" and \"Vegetables Primary\" may also be good choices for experiments)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "PO92R4l1FMoE",
        "colab": {}
      },
      "source": [
        "wheat_data = df.loc[df['Item'] == \"Wheat\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "FVvsFMbiFMoG",
        "colab": {}
      },
      "source": [
        "wheat_data.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "OyozxBDtFMoH"
      },
      "source": [
        "It looks the table also contains different aspects relating to the production of wheat. As above, we consider the unique values of the column “Element”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "b1Gg-bkVFMoI",
        "colab": {}
      },
      "source": [
        "wheat_data['Element'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "bbEJPr23FMoJ"
      },
      "source": [
        "As above, we consider the unique values of the column “Element”. Now we can form clearer ideas about the table. In the next, we consider the “Yield” (it seems to be the yield of unit land area)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "X6FxY4HdFMoJ",
        "colab": {}
      },
      "source": [
        "wheat_yield = wheat_data.loc[wheat_data[\"Element\"] == \"Yield\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "X-Wxk-lWFMoK",
        "colab": {}
      },
      "source": [
        "wheat_yield.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "_yreQp0_FMoM"
      },
      "source": [
        "Let us check the yield of a few areas in the world. Note the query to the `DataFrame` below. You can use `wheat_yield[\"Area\"].unique()` to find the area names to form your queries. Please refer to [pandas document][qry-doc] for more information about queries in `pandas`.\n",
        "\n",
        "[qry-doc]:https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "F21pS3kwFMoM",
        "colab": {}
      },
      "source": [
        "px.scatter(wheat_yield.query('Area == [\"Australia\", \"India\", \"China\", \"United States of America\"]'), \n",
        "           x=\"Year\", y=\"Value\", color=\"Area\", trendline=\"ols\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "UGz4NpkwFMoO"
      },
      "source": [
        "Well the trend looks encouraging enough to deserve a movie! :P "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "El0ruYcWFMoO",
        "colab": {}
      },
      "source": [
        "px.scatter(wheat_yield.query('Area == [\"Australia\", \"India\", \"China\", \"United States of America\"]'), \n",
        "           x=\"Year\", y=\"Value\", size=\"Value\", color=\"Area\",\n",
        "           animation_frame=\"Year\", animation_group=\"Area\", range_x=[1950, 2020], range_y=[0, 60000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "CMbKRDsCFMoQ"
      },
      "source": [
        "But there seems to be oscillations in the growth, which may deserve further investigation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "Ky-3GpgNFMoR"
      },
      "source": [
        "## Visualise and Examine the Aspect of Interest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "IC6C96xsFMoS"
      },
      "source": [
        "Let us picture the yield of wheat globally,  which both gives us first impression about the trend and looks nice for report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "a0webgSvFMoS"
      },
      "source": [
        "To generate the global picture with geographical information, we would need a list of the country code.   We have downloaded the code list with country names from the Internet. Now we want to merge this table to the food production table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "HOir2EFaFMoS",
        "colab": {}
      },
      "source": [
        "# We care only about name-code correspondence in the area-code table.\n",
        "# And we want the country-name-column are referred to consistently as \"Area\" \n",
        "# in both tables.\n",
        "iso_info_df = iso_country_df[[\"name\", \"alpha-3\"]]\\\n",
        "    .rename(columns={\"name\": \"Area\", \"alpha-3\": \"AreaAlphaCode\"})\n",
        "iso_info_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "GhispdAzFMoT"
      },
      "source": [
        "Now we merge the two tables with respect to the column of country names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "hfyLWVMtFMoT",
        "colab": {}
      },
      "source": [
        "wheat_yield_cc = pd.merge(wheat_yield, iso_info_df, on=\"Area\") # Get Area Code for Visualisation\n",
        "wheat_yield_cc.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "9gvO4E_LFMoU",
        "colab": {}
      },
      "source": [
        "px.scatter_geo(wheat_yield_cc, locations=\"AreaAlphaCode\", size=\"Value\", animation_frame=\"Year\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "d1g4fIWDFMoW"
      },
      "source": [
        "The bubbles seem to be breathing. Let's try to find out if the physical process on the earth has something to do we our food."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "hidden": true,
        "id": "qgH1SMe5FMoX"
      },
      "source": [
        "## Explore Links between two Processes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "ofTVJ2s0FMoX"
      },
      "source": [
        "Let us combine the food data with the SST data. Note we need to rename the column of \"year\" in SST data to \"Year\". The match must be exact."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "YrEW67KkFMoX",
        "colab": {}
      },
      "source": [
        "food_ocean = pd.merge(wheat_yield_cc, sst_area_mean12_df.rename(columns={\"year\": \"Year\"}), on=\"Year\")\n",
        "food_ocean.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "0QQPs0qdFMoa"
      },
      "source": [
        "The first step is to compute the increase of the production from one year to the next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "mrfX7zklFMoa",
        "colab": {}
      },
      "source": [
        "dfs = []\n",
        "for cc in [\"AUS\", \"CHN\", \"IND\", \"USA\"]:\n",
        "    df = food_ocean.loc[food_ocean.AreaAlphaCode == cc]\n",
        "    df[\"Growth\"] = df.Value.shift(-1) - df.Value # check how shift does to data frames\n",
        "    dfs.append(df)\n",
        "    \n",
        "g_df = pd.concat(dfs)\n",
        "g_df['SSTDevi'] = g_df.sst - g_df.sst.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "fNECLuO9FMob",
        "colab": {}
      },
      "source": [
        "px.scatter(g_df, x=\"Growth\", y=\"SSTDevi\", size=\"Value\", color=\"Area\", animation_frame=\"Year\",\n",
        "          range_y=[-3, +3], range_x=[-10000, 10000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "h9RUx1g7FMod"
      },
      "source": [
        "More investigation is needed.\n",
        "\n",
        "Check the following reference for more information\n",
        "\n",
        "http://www.fao.org/3/y4011e/y4011e04.htm"
      ]
    }
  ]
}